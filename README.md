# Solving-the-Online-Job-Maze
## Implementing WebCrawlers and Investigating NLP Systems to Simplify Complex Job Posts and Identify Skill Trends within the Currrent Job Market.

#### Dataset Overview

This project focuses on overcoming challenges associated with inconsistent job postings and identifying trending technical skills in the Data Science job market. The dataset was created by web scraping job postings from SEEK.com.au, targeting Data Science positions in Brisbane, Australia. The data consists of job titles, company names, locations, departments, position types, salaries, and job descriptions, which were organized into a structured dataset for further analysis.

#### Project Overview

This project involves developing a Natural Language Processing (NLP) system that applies various techniques to address two main challenges:

Standardizing and summarizing job descriptions using extractive text summarization models like TextRank, Latent Semantic Analysis (LSA), and BART.

Identifying and analyzing trending technical skills in Data Science job postings using Word2Vec.

The project demonstrates expertise in web scraping, data wrangling, NLP, and machine learning model development, with applications in improving job search experiences and understanding market demands.

#### Repository Contents

Python Code: Implementation of web scraping, data processing, and NLP techniques, including scripts used for model development and evaluation.

Written Report: A detailed report on the project's objectives, methodologies, results, and findings, including discussions on data limitations and model performance.
Source

The dataset was created using web scraping techniques from SEEK.com.au. Legal considerations, such as complying with SEEK's Terms of Service and ethical scraping practices, were observed throughout the project.

